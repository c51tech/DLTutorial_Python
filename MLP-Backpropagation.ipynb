{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "<img src='http://i.stack.imgur.com/3mnuT.png' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "### Data\n",
    "\n",
    "일반적인 분류문제에서 데이터는 다음 형태로 제공된다.  \n",
    "$ \\begin{align}\n",
    "\\mathscr{D} &= [ [\\mathbf{x}^{(1)}, C^{(1)}], [\\mathbf{x}^{(2)}, C^{(2)}], ... , [\\mathbf{x}^{(N)}, C^{(N)}] ] \\\\\n",
    "&= [\\mathbf{x}^{(n)}, C^{(n)}]^{N}_{n=1}\n",
    "\\end{align} $\n",
    "\n",
    "- input: $ \\mathbf{x} = [x_1, x_2, ..., x_{N_i}] $  \n",
    "- class: $ \\mathcal{C} = \\{C_1, C_2, ..., C_{N_k}\\} $  \n",
    "- target output: $ \\mathbf{t} = [t_1, ..., t_{N_k}] $\n",
    "\n",
    " 예)\n",
    "\n",
    "|인구($x_1$) |면적($x_2$) |국명($C$)|\n",
    "|-----------|-----------|--------|\n",
    "|100000     |2000       |미국     |\n",
    "\n",
    "\n",
    "\n",
    "예를 들어, 클래스가 {'미국', '중국', '일본'} 이라면,  \n",
    "'미국'은 $ \\mathbf{t} = [1, 0, 0] $  \n",
    "'중국'은 $ \\mathbf{t} = [0, 1, 0] $  \n",
    "'일본'은 $ \\mathbf{t} = [0, 0, 1] $  \n",
    "으로 변환한다.\n",
    "\n",
    "따라서 학습에 사용될 데이터 는 다음과 같이 변환한다.  \n",
    "$ \\mathscr{D} = [ [\\mathbf{x}^{(1)}, \\mathbf{t}^{(1)}], [\\mathbf{x}^{(2)}, \\mathbf{t}^{(2)}], ... , [\\mathbf{x}^{(N)}, \\mathbf{t}^{(N)}]  ] $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron\n",
    "For each neuron j,  \n",
    "\n",
    "- output: $ o_j = \\sigma(\\mathtt{net}_j) $  \n",
    "- activation function: $ \\sigma(\\cdot) $  \n",
    "- weighted sum to neuron $j$: $\\mathtt{net}_j = b_j + \\sum_{i=1}^{N_i}{w_{ij}o_i}$  \n",
    "- bias of neuron $j$: $b_j$  \n",
    "- weight from neuron $i$ to neuron $j$: $w_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "input: $ \\mathbf{x} = [x_1, ..., x_i, ... , x_{N_i}] $  \n",
    "hidden: $ \\mathbf{h} = [h_1, ..., h_j, ... , h_{N_j}] $  \n",
    "actual output: $ \\mathbf{y} = [y_1, ..., y_k, ... , y_{N_k}] $  \n",
    "\n",
    "$i$ : index for input neurons  \n",
    "$j$ : index for hidden neurons  \n",
    "$k$ : index for output neurons  \n",
    "\n",
    "$h_j = \\sigma(\\mathtt{net}_j) = \\sigma(b_j + \\sum_{i=0}^{N_i}{w_{ij}x_i}) $  \n",
    "$y_k = \\sigma(\\mathtt{net}_k) = \\sigma(b_k + \\sum_{j=0}^{N_j}{w_{jk}h_j}) $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Backpropagation)  \n",
    "[참고 1](http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html)  \n",
    "[참고 2](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [theano]",
   "language": "python",
   "name": "Python [theano]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
