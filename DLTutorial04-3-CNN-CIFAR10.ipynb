{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial 04: CNN - Object Recognition with CIFAR-10 (Ch21)\n",
    "\n",
    "from Deep Learning with Python by Jason Brownlee (2016)\n",
    "[e-book](https://machinelearningmastery.com/deep-learning-with-python/)\n",
    "[요약](http://machinelearningmastery.com/introduction-python-deep-learning-library-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 Project Object Recognition in Photographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.1 Photograph Object Recognition Dataset\n",
    "\n",
    "[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html)  \n",
    "- 60,000 photos, 10 classes\n",
    "- training: 50,000\n",
    "- test: 10,000\n",
    "- rgb\n",
    "- 32x32\n",
    "\n",
    "[Classification Results](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 21.2 Loading The CIFAR-10 Dataset in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot ad hoc CIFAR10 instances\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "from scipy.misc import toimage\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# create a grid of 3x3 images\n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(toimage(X_train[i]))\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 181460\r\n",
      "drwxrwxr-x 3 kikim kikim      4096  7월 23 14:34 .\r\n",
      "drwxrwxr-x 3 kikim kikim      4096  7월  8 02:08 ..\r\n",
      "drwxr-xr-x 2 kikim kikim      4096  6월  5  2009 cifar-10-batches-py\r\n",
      "-rw-rw-r-- 1 kikim kikim 170498071  7월 23 14:34 cifar-10-batches-py.tar.gz\r\n",
      "-rw-rw-r-- 1 kikim kikim  15296311  7월  8 02:09 mnist.pkl.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ~/.keras/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.3 Simple CNN for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('before one-hot-encode: y_train[0, :]=', array([6], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('before one-hot-encode: y_train[0, :]=', y_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('after one-hot-encode: y_train[0, :]=', array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]))\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print('after one-hot-encode: y_train[0, :]=', y_train[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p152 스크린샷 추가할 것!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the baseline model\n",
    "def buildBaselineModel():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(3, 32, 32), \n",
    "                            border_mode='same', activation='relu', \n",
    "                            W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', \n",
    "                            border_mode='same', W_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_6 (Convolution2D)  (None, 32, 32, 32)    896         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32, 32, 32)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 32, 32, 32)    9248        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 16, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 8192)          0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           4194816     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 512)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            5130        dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4210090\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "\n",
    "model = buildBaselineModel()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "9s - loss: 1.6791 - acc: 0.3938 - val_loss: 1.3456 - val_acc: 0.5206\n",
      "Epoch 2/25\n",
      "8s - loss: 1.2960 - acc: 0.5389 - val_loss: 1.1769 - val_acc: 0.5772\n",
      "Epoch 3/25\n",
      "8s - loss: 1.1304 - acc: 0.5970 - val_loss: 1.0630 - val_acc: 0.6180\n",
      "Epoch 4/25\n",
      "9s - loss: 1.0126 - acc: 0.6384 - val_loss: 1.0210 - val_acc: 0.6374\n",
      "Epoch 5/25\n",
      "9s - loss: 0.9183 - acc: 0.6741 - val_loss: 0.9726 - val_acc: 0.6541\n",
      "Epoch 6/25\n",
      "8s - loss: 0.8403 - acc: 0.7030 - val_loss: 0.9420 - val_acc: 0.6641\n",
      "Epoch 7/25\n",
      "8s - loss: 0.7704 - acc: 0.7276 - val_loss: 0.9271 - val_acc: 0.6748\n",
      "Epoch 8/25\n",
      "8s - loss: 0.7133 - acc: 0.7480 - val_loss: 0.9159 - val_acc: 0.6823\n",
      "Epoch 9/25\n",
      "8s - loss: 0.6611 - acc: 0.7670 - val_loss: 0.9171 - val_acc: 0.6862\n",
      "Epoch 10/25\n",
      "9s - loss: 0.6132 - acc: 0.7825 - val_loss: 0.9172 - val_acc: 0.6888\n",
      "Epoch 11/25\n",
      "9s - loss: 0.5684 - acc: 0.7998 - val_loss: 0.9258 - val_acc: 0.6913\n",
      "Epoch 12/25\n",
      "9s - loss: 0.5265 - acc: 0.8140 - val_loss: 0.9523 - val_acc: 0.6905\n",
      "Epoch 13/25\n",
      "9s - loss: 0.4984 - acc: 0.8237 - val_loss: 0.9327 - val_acc: 0.6921\n",
      "Epoch 14/25\n",
      "9s - loss: 0.4619 - acc: 0.8355 - val_loss: 0.9684 - val_acc: 0.6926\n",
      "Epoch 15/25\n",
      "9s - loss: 0.4317 - acc: 0.8475 - val_loss: 0.9725 - val_acc: 0.6918\n",
      "Epoch 16/25\n",
      "9s - loss: 0.4085 - acc: 0.8551 - val_loss: 0.9596 - val_acc: 0.6975\n",
      "Epoch 17/25\n",
      "9s - loss: 0.3849 - acc: 0.8656 - val_loss: 0.9872 - val_acc: 0.6963\n",
      "Epoch 18/25\n",
      "9s - loss: 0.3624 - acc: 0.8699 - val_loss: 0.9864 - val_acc: 0.6987\n",
      "Epoch 19/25\n",
      "9s - loss: 0.3428 - acc: 0.8784 - val_loss: 1.0100 - val_acc: 0.7004\n",
      "Epoch 20/25\n",
      "9s - loss: 0.3288 - acc: 0.8845 - val_loss: 1.0204 - val_acc: 0.6995\n",
      "Epoch 21/25\n",
      "9s - loss: 0.3062 - acc: 0.8926 - val_loss: 1.0292 - val_acc: 0.6990\n",
      "Epoch 22/25\n",
      "9s - loss: 0.2962 - acc: 0.8950 - val_loss: 1.0188 - val_acc: 0.7012\n",
      "Epoch 23/25\n",
      "9s - loss: 0.2798 - acc: 0.9012 - val_loss: 1.0578 - val_acc: 0.6994\n",
      "Epoch 24/25\n",
      "9s - loss: 0.2687 - acc: 0.9055 - val_loss: 1.0547 - val_acc: 0.7024\n",
      "Epoch 25/25\n",
      "9s - loss: 0.2542 - acc: 0.9111 - val_loss: 1.0619 - val_acc: 0.7020\n",
      "Accuracy: 70.20%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          nb_epoch=epochs, batch_size=32, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_8 (Convolution2D)  (None, 32, 32, 32)    896         convolution2d_input_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 32, 32, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 32, 32, 32)    9248        dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 32, 16, 16)    0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 64, 16, 16)    18496       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 64, 16, 16)    0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 64, 16, 16)    36928       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 64, 8, 8)      0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 128, 8, 8)     73856       maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 128, 8, 8)     0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 128, 8, 8)     147584      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 128, 4, 4)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 2048)          0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 2048)          0           flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1024)          2098176     dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 1024)          0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 512)           524800      dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 512)           0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 10)            5130        dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2915114\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the Larger model\n",
    "def buildLargerModel():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(3, 32, 32), activation='relu', border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "\n",
    "model = buildLargerModel()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s - loss: 1.9125 - acc: 0.2911 - val_loss: 1.5976 - val_acc: 0.4215\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 11s - loss: 1.4983 - acc: 0.4518 - val_loss: 1.3104 - val_acc: 0.5176\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 11s - loss: 1.3150 - acc: 0.5232 - val_loss: 1.2134 - val_acc: 0.5670\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 11s - loss: 1.1841 - acc: 0.5748 - val_loss: 1.1052 - val_acc: 0.5987\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 11s - loss: 1.0845 - acc: 0.6111 - val_loss: 1.0470 - val_acc: 0.6267\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.9939 - acc: 0.6444 - val_loss: 0.9344 - val_acc: 0.6652\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.9171 - acc: 0.6753 - val_loss: 0.8765 - val_acc: 0.6963\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.8653 - acc: 0.6937 - val_loss: 0.8449 - val_acc: 0.7046\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.8130 - acc: 0.7126 - val_loss: 0.8058 - val_acc: 0.7183\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.7609 - acc: 0.7331 - val_loss: 0.7814 - val_acc: 0.7282\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.7241 - acc: 0.7439 - val_loss: 0.7515 - val_acc: 0.7393\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.6907 - acc: 0.7545 - val_loss: 0.7294 - val_acc: 0.7494\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.6601 - acc: 0.7666 - val_loss: 0.7284 - val_acc: 0.7440\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.6311 - acc: 0.7762 - val_loss: 0.7123 - val_acc: 0.7539\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.6094 - acc: 0.7858 - val_loss: 0.6940 - val_acc: 0.7662\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.5844 - acc: 0.7922 - val_loss: 0.6886 - val_acc: 0.7647\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.5635 - acc: 0.7989 - val_loss: 0.6868 - val_acc: 0.7660\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.5439 - acc: 0.8049 - val_loss: 0.6698 - val_acc: 0.7712\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.5203 - acc: 0.8152 - val_loss: 0.6630 - val_acc: 0.7741\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.5072 - acc: 0.8199 - val_loss: 0.6606 - val_acc: 0.7740\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.4910 - acc: 0.8256 - val_loss: 0.6534 - val_acc: 0.7782\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.4705 - acc: 0.8341 - val_loss: 0.6488 - val_acc: 0.7776\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.4629 - acc: 0.8355 - val_loss: 0.6476 - val_acc: 0.7809\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.4424 - acc: 0.8414 - val_loss: 0.6556 - val_acc: 0.7800\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 11s - loss: 0.4278 - acc: 0.8489 - val_loss: 0.6445 - val_acc: 0.7858\n",
      "LargerModel Accuracy: 78.58%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs,\n",
    "batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"LargerModel Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가\n",
    "학습된 모델이 테스트 데이터의 클래스를 뭐라고 예측해보는지 직접 확인해보자.\n",
    "[Keras - The Sequential model API](http://keras.io/models/sequential/)의 predict()와 predict_classes()로 실행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(ori_X_train, ori_y_train), (ori_X_test, ori_y_test) = cifar10.load_data()\n",
    "\n",
    "classNames = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "              'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_test = ori_X_test.astype('float32')\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# get random test example index to predict\n",
    "from numpy import random\n",
    "rIdx = int(random.rand()*9990)\n",
    "\n",
    "# predict some test examples\n",
    "pred_Y_test = model.predict_classes(X_test[rIdx:rIdx+9], batch_size=32, verbose=2)\n",
    "\n",
    "# show example images and expected-precdicted classes\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle(u\"Test Examples: %d ~ %d\\n  \" % (rIdx, rIdx + 8), fontsize=18)\n",
    "for i in range(0, 9):\n",
    "    ax = fig.add_subplot(330 + 1 + i)\n",
    "    ax.imshow(toimage(ori_X_test[rIdx+i]))\n",
    "    ax.set_title(u'%s-%s' % (classNames[ori_y_test[rIdx+i,0]], classNames[pred_Y_test[i]]))\n",
    "    ax.set_xticks([])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [theano]",
   "language": "python",
   "name": "Python [theano]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
