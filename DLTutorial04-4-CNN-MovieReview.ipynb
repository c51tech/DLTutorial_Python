{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial 04: CNN - Sentiment Analysis from Movie Reviews (Ch22)\n",
    "\n",
    "from Deep Learning with Python by Jason Brownlee (2016)\n",
    "[e-book](https://machinelearningmastery.com/deep-learning-with-python/)\n",
    "[요약](http://machinelearningmastery.com/introduction-python-deep-learning-library-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 22 Project: Predict Sentiment From Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.1 Movie Review Sentiment Classification Dataset\n",
    "\n",
    "[IMDB 데이터셋 홈페이지](http://www.cs.toronto.edu/~kriz/cifar.html), [데이터 파일](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)\n",
    "- Movie Reviews (Positive or Negative)\n",
    "- training: 25,000\n",
    "- test: 25,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 22.2 Load the IMDB Dataset With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kikim/anaconda2/envs/theano/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl\n",
      "33202176/33213513 [============================>.] - ETA: 0stotal 213900\n",
      "drwxrwxr-x 3 kikim kikim      4096  7월 31 17:22 .\n",
      "drwxrwxr-x 3 kikim kikim      4096  7월  8 02:08 ..\n",
      "drwxr-xr-x 2 kikim kikim      4096  6월  5  2009 cifar-10-batches-py\n",
      "-rw-rw-r-- 1 kikim kikim 170498071  7월 23 14:34 cifar-10-batches-py.tar.gz\n",
      "-rw-rw-r-- 1 kikim kikim  33213513  7월 31 17:39 imdb.pkl\n",
      "-rw-rw-r-- 1 kikim kikim  15296311  7월  8 02:09 mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(test_split=0)\n",
    "\n",
    "!ls -al ~/.keras/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(25000,)\n",
      "(25000,)\n",
      "X_train[0]:\n",
      "[1, 20, 28, 716, 48, 495, 79, 27, 493, 8, 5067, 7, 50, 5, 4682, 13075, 10, 5, 852, 157, 11, 5, 1716, 3351, 10, 5, 500, 7308, 6, 33, 256, 41, 13610, 7, 17, 23, 48, 1537, 3504, 26, 269, 929, 18, 68709, 7, 22565, 4284, 8, 105, 5, 22396, 182, 314, 38, 98, 103, 7, 36, 2184, 246, 360, 7, 19, 396, 17, 26, 269, 929, 18, 1769, 493, 6, 116, 7, 105, 5, 575, 182, 27, 5, 1002, 1085, 130, 62, 17, 24, 89, 17, 13, 381, 1421, 8, 5167, 7, 5, 2723, 38, 325, 7, 17, 23, 93, 9, 156, 252, 19, 235, 20, 28, 5, 104, 76, 7, 17, 169, 35, 14764, 17, 23, 1460, 7, 36, 2184, 934, 56, 2134, 6, 17, 891, 214, 11, 5, 1552, 6, 92, 6, 33, 256, 82, 7]\n",
      "y_train[0]:\n",
      "1\n",
      "Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"X_train[0]:\")\n",
    "print(X_train[0])\n",
    "\n",
    "print(\"y_train[0]:\")\n",
    "print(y_train[0])\n",
    "\n",
    "# Summarize number of classes\n",
    "print(\"Classes: %s\" % numpy.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 102099\n",
      "Review length: Mean 285.84 words (212.622320)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2eb02def10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize number of words\n",
    "print(\"Number of words: %d\" % len(numpy.unique(numpy.hstack(X_train))))\n",
    "\n",
    "# Summarize review length\n",
    "result = map(len, X_train)\n",
    "print(\"Review length: Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "\n",
    "# plot review length as a boxplot and histogram\n",
    "pyplot.subplot(121)\n",
    "pyplot.boxplot(result)\n",
    "pyplot.subplot(122)\n",
    "pyplot.hist(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.3 Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Word2Vec](http://deeplearning4j.org/kr-word2vec)  \n",
    "[Keras embedding](https://keras.io/layers/embeddings/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.4 Simple Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "test_split = 0.33\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(\n",
    "    nb_words=top_words, test_split=test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train.shape', (16750,))\n",
      "('X_train.shape', [1, 20, 28, 716, 48, 495, 79, 27, 493, 8, 2, 7, 50, 5, 4682, 2, 10, 5, 852, 157, 11, 5, 1716, 3351, 10, 5, 500, 2, 6, 33, 256, 41, 2, 7, 17, 23, 48, 1537, 3504, 26, 269, 929, 18, 2, 7, 2, 4284, 8, 105, 5, 2, 182, 314, 38, 98, 103, 7, 36, 2184, 246, 360, 7, 19, 396, 17, 26, 269, 929, 18, 1769, 493, 6, 116, 7, 105, 5, 575, 182, 27, 5, 1002, 1085, 130, 62, 17, 24, 89, 17, 13, 381, 1421, 8, 2, 7, 5, 2723, 38, 325, 7, 17, 23, 93, 9, 156, 252, 19, 235, 20, 28, 5, 104, 76, 7, 17, 169, 35, 2, 17, 23, 1460, 7, 36, 2184, 934, 56, 2134, 6, 17, 891, 214, 11, 5, 1552, 6, 92, 6, 33, 256, 82, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_train.shape\", X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train.shape', (16750, 500))\n",
      "('X_train.shape', array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    1,   20,   28,\n",
      "        716,   48,  495,   79,   27,  493,    8,    2,    7,   50,    5,\n",
      "       4682,    2,   10,    5,  852,  157,   11,    5, 1716, 3351,   10,\n",
      "          5,  500,    2,    6,   33,  256,   41,    2,    7,   17,   23,\n",
      "         48, 1537, 3504,   26,  269,  929,   18,    2,    7,    2, 4284,\n",
      "          8,  105,    5,    2,  182,  314,   38,   98,  103,    7,   36,\n",
      "       2184,  246,  360,    7,   19,  396,   17,   26,  269,  929,   18,\n",
      "       1769,  493,    6,  116,    7,  105,    5,  575,  182,   27,    5,\n",
      "       1002, 1085,  130,   62,   17,   24,   89,   17,   13,  381, 1421,\n",
      "          8,    2,    7,    5, 2723,   38,  325,    7,   17,   23,   93,\n",
      "          9,  156,  252,   19,  235,   20,   28,    5,  104,   76,    7,\n",
      "         17,  169,   35,    2,   17,   23, 1460,    7,   36, 2184,  934,\n",
      "         56, 2134,    6,   17,  891,  214,   11,    5, 1552,    6,   92,\n",
      "          6,   33,  256,   82,    7], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_train.shape\", X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           4000250     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             251         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4160501\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def buildSimpleModel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = buildSimpleModel()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16750 samples, validate on 8250 samples\n",
      "Epoch 1/2\n",
      "16750/16750 [==============================] - 0s - loss: 0.5620 - acc: 0.6776 - val_loss: 0.3419 - val_acc: 0.8568\n",
      "Epoch 2/2\n",
      "16750/16750 [==============================] - 0s - loss: 0.2028 - acc: 0.9219 - val_loss: 0.3298 - val_acc: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e5f6e3310>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          nb_epoch=2, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Accuracy: 86.25%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Simple Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.5 One-Dimensional Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 500, 32)       160000      embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 500, 32)       3104        embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 250, 32)       0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 8000)          0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 250)           2000250     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             251         dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2163605\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "def buildConv1D():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "    model.add(Convolution1D(nb_filter=32, filter_length=3, \n",
    "                            border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = buildConv1D()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16750 samples, validate on 8250 samples\n",
      "Epoch 1/2\n",
      "16750/16750 [==============================] - 1s - loss: 0.5210 - acc: 0.7026 - val_loss: 0.3164 - val_acc: 0.8668\n",
      "Epoch 2/2\n",
      "16750/16750 [==============================] - 1s - loss: 0.2545 - acc: 0.8979 - val_loss: 0.3047 - val_acc: 0.8739\n",
      "Conv1D Model Accuracy: 87.39%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          nb_epoch=2, batch_size=128, verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Conv1D Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [theano]",
   "language": "python",
   "name": "Python [theano]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
